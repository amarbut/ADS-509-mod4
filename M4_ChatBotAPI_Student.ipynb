{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86199608-2122-4aed-add2-9350df766072",
   "metadata": {},
   "source": [
    "# ADS-509 Assignment 4.1\n",
    "## LLM Chatbot\n",
    "\n",
    "**Student Version** \n",
    "\n",
    "In this assignment you will work with an AI Assistant of your choice to build a Data Science Chatbot. Remember that USD students all have access to Gemini Pro, though you should feel free to use whichever assistant you prefer. Since you will be working with an AI Assistant, this assignment notebook doesn't have the same kind of code scaffolding that previous assignments had, and your written questions will be largely reflections on your interactions with the AI Assistant. However, the general expectations are the same.\n",
    "\n",
    "Work through this notebook as if it were a worksheet, completing the code sections marked with **TODO** in the cells provided. Similarly, written questions will be marked by a \"Q:\" and will have a corresponding \"A:\" spot for you to fill in with your answers. **Make sure to answer every question marked with a Q: for full credit**.\n",
    "\n",
    "Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential import statements and make sure that all such statements are moved into the designated cell.\n",
    "\n",
    "A .pdf of this notebook, with your completed code and written answers, is what you should submit in Canvas for full credit. **DO NOT SUBMIT A NEW NOTEBOOK FILE OR A RAW .PY FILE**. Submitting in a different format makes it difficult to grade your work, and students who have done this in the past inevitably miss some of the required work or written questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fd6d37-01e2-4ad9-9950-bb2b1333fd04",
   "metadata": {},
   "source": [
    "## API Connection and Import\n",
    "\n",
    "We will be using the huggingface inference API for this assignment. Once you make an account, everyone receives $0.10 in free credits for using the API each month, which will get you somewhere around 100 calls to a chatbot-style model (depending on which model you use). Please be careful with the free credits that you have available, but we understand that debugging can sometimes rack up quite a few calls. \n",
    "\n",
    "You can purchase a PRO subscription for \\\\$9 per month which will get you another \\\\$2 of credits, but if you run out of free credits and don't want to purchase a subscription, let your instructor know and complete the rest of the assignment with a locally hosted model.\n",
    "\n",
    "**TODO**:\n",
    "\n",
    "- Use the huggingface_hub.InferenceClient to connect to the API\n",
    "- I recommend using the \"hf-inference\" server\n",
    "\n",
    "**Q**: What prompt did you give your AI Assistant to set up the connection? Did you need to do any follow up conversation to complete this first step? What changes might you make to your initial prompt to make it more efficient?\n",
    "\n",
    "**A**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b89324-576c-4a25-ab50-87b17c1fcacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Connect to the huggingface inference API\n",
    "??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef3b23c-7143-4197-bd2e-4f663693e272",
   "metadata": {},
   "source": [
    "## Basic Chatbot Function\n",
    "\n",
    "**TODO**:\n",
    "\n",
    "- Define a `build_prompt` function that properly formats text for use with a huggingface chatbot. It should be able to take both a system message and a user message.\n",
    "- Connect to a model that is appropriate for a chatbot (I recommend the \"HuggingFaceTB/SmolLM3-3B\" model)\n",
    "- Query the chatbot with the system message and user message provided in the cell below\n",
    "- Print the chatbot response\n",
    "\n",
    "**Q**: What is the difference between a system message and a user message?\n",
    "\n",
    "**A**: A system message is appended to the beginning of a query and should provide overall guidance on the chatbot's role and behavior. In a longer conversation or established chatbot, this message will be static, where the user query will change with every interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fed3b9-0333-419a-8534-a0126dcff394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define a function that formats the chatbot query text\n",
    "\n",
    "def build_prompt(system_message: str, user_message: str):\n",
    "    ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e71ff7-a171-400b-8dc8-bc0bd111e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: connect to a chatbot model and retrieve the response for the following query\n",
    "\n",
    "system_message =  \"You are a helpful assistant.\"\n",
    "user_message = \"I need to understand this quarter's sales numbers in relation to our company KPIs.\"\n",
    "\n",
    "??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb953830-9586-46ee-8fb7-d94f71d36c7b",
   "metadata": {},
   "source": [
    "# Using system instructions \n",
    "\n",
    "\"You are a helpful assistant\" is often the default system instruction for a chatbot model, but does not give a lot of specific guidance for how the chatbot should respond. This system message can be adjusted to change the content of the responses and also drive other behaviors like asking for follow-up information.\n",
    "\n",
    "**TODO**:\n",
    "\n",
    "- Use the provided system instructions and user queries below to interact with your chatbot and reflect on the effect.\n",
    "\n",
    "**Q**: Were the system instructions effective in adjusting the model behavior? Do you see any issues with the chatbot interaction/conversation so far?\n",
    "\n",
    "**A**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a9562a-c307-4a9f-8ae3-06e105dab290",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an internal Data Science bot. Always ask for the department and user role before giving troubleshooting advice.\"\n",
    "user_message = \"I need to understand this quarter's sales numbers in relation to our department KPIs.\"\n",
    "\n",
    "??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aa2590-2851-4ce4-b402-bd3f5f7806f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = \"Sure, I am a Data Analyst in the Marketing department.\"\n",
    "\n",
    "??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2927cf52-b20c-4edd-b527-db92d9f6b94a",
   "metadata": {},
   "source": [
    "## Create a Conversation\n",
    "\n",
    "The API interaction is stateless, so the model doesn't have any \"memory\" of what you've discussed unless you provide it.\n",
    "\n",
    "**TODO**:\n",
    "\n",
    "- Use your AI-Assistant to create a class called `ChatSession`\n",
    "- The input for this class should be: your system prompt, model id, and huggingface API key\n",
    "- The class should have a `send` function that takes in a new user query and returns a reply that uses the entire conversation and system instructions as context\n",
    "- Use the provided queries to debug and test your chatbot function.\n",
    "\n",
    "**Q**: How many messages with your AI Assistant did it take to create your ChatSession class? What issues did you run into and how did you fix them?\n",
    "\n",
    "**A**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6facd95d-e5a9-4b92-9689-d15240682cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the ChatSession class\n",
    "\n",
    "class ChatSession:\n",
    "    def __init__(??):\n",
    "        ??\n",
    "    \n",
    "    def send(self, user_input: str, temperature: float = 0.7) -> str:\n",
    "        ??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c0937a-a7d9-4233-ac61-dbff94a4a4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb807d96-a17a-4ed6-9985-38866cbe4819",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply1 = session.send(\"I need to understand this quarter's sales numbers in relation to our company KPIs.\")\n",
    "print(\"Assistant:\", reply1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d8a7df-3770-42aa-b875-ed45f370059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply2 = session.send(\"Sure, I am a Data Analyst in the Marketing department\")\n",
    "print(\"Assistant:\", reply2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81671d09-454d-4aa6-bf50-8842bfc3b8be",
   "metadata": {},
   "source": [
    "## Integrating RAG (Retrieval Augmented Generation)\n",
    "\n",
    "An internal chatbot would be likely to use a method like RAG to integrate company documents into its responses. \n",
    "\n",
    "**TODO**:\n",
    "\n",
    "- Use the langchain library to implement RAG in two ways:\n",
    "  1. Using the provided list of strings as your RAG documents\n",
    "  2. Using the provided folder of .txt files as your RAG documents\n",
    "- You are not required to integrate the RAG into your ChatSession class unless you would like to do so (i.e. a single query with RAG implemented is sufficient).\n",
    "\n",
    "**Q**: If you integrated the RAG with your ChatSession class, what issues did you run into when editing with the AI-Assistant? If you implemented a single query RAG chatbot, what would you need to consider to integrate the RAG functionality in the ChatSession conversation concept?\n",
    "\n",
    "**A**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac399c85-db04-4008-a1c4-62c8174aff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement a RAG that uses the provided strings as documents\n",
    "\n",
    "docs = [\n",
    "    \"The Marketing team tracks click-through rate (CTR) as a key performance indicator (KPI) to measure campaign effectiveness.\",\n",
    "    \"Our data science workflow includes collecting raw data, cleaning it, and then training predictive models using Python and scikit-learn.\",\n",
    "    \"Customer support tickets are stored in a PostgreSQL database, and an analyst can query recent records to help identify common issues.\"\n",
    "]\n",
    "\n",
    "user_message = \"I'm an analyst in the Marketing department. What kinds of analyses can I do to support my team's KPIs?\"\n",
    "\n",
    "??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7804c118-6dc2-4f19-9df6-f2196bb514ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement a RAG that uses the provided folder of .txt files (RAG_docs) as documents\n",
    "\n",
    "query = \"I'm an analyst in the Marketing department. What kinds of analyses can I do to support my team's KPIs?\"\n",
    "\n",
    "??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33a0930-1070-48ad-9272-aadb1e64b9d0",
   "metadata": {},
   "source": [
    "# Generate Chat Log\n",
    "\n",
    "For a Data Science chatbot, you might not need to keep track of conversations or perform any meta-analyses. However, for many internal chatbots, like a customer service or IT chatbot, creating a log for future analysis can add a lot of value (plus, as data scientists, we always want to be able to run meta-analyses, right?).\n",
    "\n",
    "**TODO**:\n",
    "\n",
    "- Create a function `generate_keywords_with_llm` that uses the huggingface chatbot API to create a list of keywords for a query/reply pair\n",
    "- Use these keywords to create a log for the query/reply pair\n",
    "- Feel free to integrate this logging function with the RAG or ChatSession work that you did above, though it is not required.\n",
    "\n",
    "**Q**: Give a written description of how your query-response-log pipeline works. For example, where does the RAG occur, what gets fed into the LLM, are there multiple instances of LLMs involved?\n",
    "\n",
    "**A**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4423a926-ad79-4360-8c6a-98b5d9040bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define a function to extract keywords from a conversation\n",
    "\n",
    "def generate_keywords_with_llm(??):    \n",
    "    ??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8291eb6a-453d-43ee-ae48-c64c6e66a037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define a function that creates a log for a conversation\n",
    "\n",
    "def create_log(??):\n",
    "    ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2f1ae2-b28b-40bb-b2b9-f9b98410dfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use the following query to demonstrate your keyword labeling and logging functions\n",
    "\n",
    "query = \"How should I start my analysis of the new marketing CTR data?\"\n",
    "\n",
    "??\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
